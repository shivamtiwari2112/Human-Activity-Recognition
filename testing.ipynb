{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv = pd.read_csv('./Testing_set.csv')\n",
    "# test_path='./test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.2.2 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model= pickle.load(open('./results/model.pkl','rb'))\n",
    "le= pickle.load(open('./results/label_encoder.pkl','rb'))\n",
    "scaler= pickle.load(open('./results/scaler.pkl','rb'))\n",
    "pca= pickle.load(open('./results/pca.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_color_histogram(image_path, bins=(8, 8, 8)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "    return [0]\n",
    "\n",
    "def extract_lbp_features(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 10))\n",
    "    return lbp.flatten()\n",
    "    return [0]\n",
    "\n",
    "def extract_sift_features(image_path,max_keypoints=100):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if len(keypoints) > max_keypoints:\n",
    "        keypoints = sorted(keypoints, key=lambda x: x.response, reverse=True)[:max_keypoints]\n",
    "        descriptors = sift.compute(image, keypoints)[1]\n",
    "\n",
    "    # Flatten and normalize descriptors to ensure a consistent feature vector size\n",
    "    sift_features = descriptors.flatten()\n",
    "    if len(sift_features) < max_keypoints * 128:\n",
    "        sift_features = np.concatenate([sift_features, np.zeros(max_keypoints * 128 - len(sift_features))])\n",
    "\n",
    "    return sift_features.flatten() \n",
    "    return [0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(img_path):\n",
    "    \n",
    "\n",
    "    # Extract HOG features\n",
    "    img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    im2 = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "#         im2=[0]\n",
    "    # Extract color histogram features\n",
    "    color_hist = extract_color_histogram(img_path)\n",
    "    \n",
    "    # Extract LBP features\n",
    "    lbp_features = extract_lbp_features(img_path)\n",
    "    \n",
    "    # Extract SIFT features\n",
    "    sift_features = extract_sift_features(img_path)\n",
    "    \n",
    "    # Combine features horizontally\n",
    "    combined_features = np.hstack((im2, color_hist, lbp_features, sift_features))\n",
    "    \n",
    "    return combined_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_imgs=[\"./Image_4.jpg\",\"./Image_23.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data=[]\n",
    "for img_path in testing_imgs:\n",
    "    testing_data.append(data(img_path))\n",
    "\n",
    "testing_data=np.array(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "testing_data=scaler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca\n",
    "testing_data=pca.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texting' 'laughing']\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "y_pred=model.predict(testing_data)\n",
    "\n",
    "#encoding\n",
    "y_pred=le.inverse_transform(y_pred)\n",
    "\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
